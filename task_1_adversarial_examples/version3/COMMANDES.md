# Commandes Rapides - Phase 1

## ğŸš€ ExÃ©cution (3 commandes essentielles)

```bash
# 1. VÃ©rifier que tout est prÃªt
cd /p/home/jusers/ansart1/jureca/code/task_1_adversarial_examples/version3
python preflight_check.py

# 2. Lancer l'attaque sur GPU A100 (60-90 min)
sbatch run_solver.sh

# 3. Surveiller la progression
python monitor.py
```

---

## ğŸ“Š Surveillance en temps rÃ©el

```bash
# Dashboard complet (relancer pour rafraÃ®chir)
python monitor.py

# Logs en temps rÃ©el
tail -f logs/slurm_*.out

# Statut SLURM
squeue -u $USER

# Stats rapides JSON
cat logs/stats_summary.json
```

---

## ğŸ” Analyse des rÃ©sultats

```bash
# Analyse locale (rapide, sans API)
python analyze.py output/submission_run1.npz --mode local

# Analyse avec API (score rÃ©el, limite: 15 min entre appels)
python analyze.py output/submission_run1.npz --mode api
```

---

## ğŸ“¤ Soumission

```bash
# Soumettre au leaderboard (limite: 5 min entre soumissions)
python submit.py output/submission_run1.npz

# Obtenir logits + soumettre (avec pause automatique)
python submit.py output/submission_run1.npz --action both
```

---

## ğŸ“ Fichiers importants

### EntrÃ©e
- `../natural_images.pt` - Dataset (100 images 28Ã—28Ã—3)

### Sortie
- `output/submission_run1.npz` - Exemples adverses (Ã  soumettre)

### Logs JSON (Ã©tat persistant)
- `logs/local_state.json` - Meilleur rÃ©sultat par image
- `logs/run_history.json` - Historique complet
- `logs/stats_summary.json` - Stats rapides

### Logs SLURM
- `logs/slurm_<job_id>.out` - Sortie du job
- `logs/slurm_<job_id>.err` - Erreurs (vide si OK)

---

## ğŸ“ˆ InterprÃ©tation des rÃ©sultats

### Sortie de `analyze.py --mode api`:

```
Success Rate: 87/100 (87.0%)          â† 87% d'attaques rÃ©ussies
Leaderboard Score: 0.1876             â† Score final (Ã  minimiser)
  Successful only:   0.1234           â† L2 moyen des succÃ¨s
  Failed (all 1.0):  1.0000           â† PÃ©nalitÃ© pour Ã©checs

Per-Image Results:
 ID | True | Pred | Status  | L2 Raw   | Score
-------------------------------------------------
  0 |   42 |   17 | SUCCESS |   4.2314 | 0.1460  â† RÃ©ussi, L2 faible
  2 |   88 |   88 | FAILED  |   5.1234 | 1.0000  â† Ã‰chouÃ©, pÃ©nalisÃ©
```

### MÃ©triques cibles:
- **Success rate API**: >85% (objectif)
- **L2 normalisÃ© moyen**: <0.15 (pour succÃ¨s)
- **Leaderboard score**: <0.20 (compÃ©titif)

---

## ğŸ› DÃ©pannage

### Job bloquÃ© dans la queue

```bash
# VÃ©rifier l'Ã©tat de la partition
sinfo -p dc-gpu-devel

# Si trop de nÅ“uds down, utiliser partition principale
# Ã‰diter run_solver.sh:
#SBATCH --partition=dc-gpu
#SBATCH --time=04:00:00
```

### Job Ã©choue immÃ©diatement

```bash
# Voir les erreurs
tail -n 50 logs/slurm_*.err

# Causes courantes:
# - Module PyTorch non chargÃ© (gÃ©rÃ© auto par script)
# - Fichier natural_images.pt introuvable
# - Mauvaise partition (utiliser dc-gpu ou dc-gpu-devel)
```

### Taux de succÃ¨s API faible (<70%)

**Diagnostic**: Attaques ne transfÃ¨rent pas vers le black-box.

**Solution Phase 2**: Calibration automatique des kappas.

**Fix manuel temporaire**:
1. Identifier images Ã©chouÃ©es: `python analyze.py ... --mode api | grep FAILED`
2. Ã‰diter `logs/local_state.json`:
   ```json
   {
     "images": {
       "42": {
         "kappa": 5.0,  â† Augmenter (Ã©tait 0.0)
         ...
       }
     }
   }
   ```
3. Relancer: `sbatch run_solver.sh`

---

## âš™ï¸ Personnalisation

### Modifier paramÃ¨tres d'attaque

Ã‰diter `run_solver.sh`:

```bash
# Plus agressif (attaques plus fortes)
--epsilon-max 15.0 \
--restarts 20 \
--pgd-steps 200

# Plus rapide (qualitÃ© lÃ©gÃ¨rement moindre)
--restarts 10 \
--pgd-steps 100 \
--bs-steps 5

# Plage epsilon personnalisÃ©e
--epsilon-min 1.0 \
--epsilon-max 10.0
```

### Nom de fichier personnalisÃ©

```bash
python main_solver.py --save-name mon_experience.npz
```

---

## ğŸ“Š Structure de `local_state.json`

```json
{
  "num_runs": 2,
  "last_update": "2025-11-23T14:30:00",
  "images": {
    "0": {
      "best_l2": 4.2314,      â† Meilleur L2 trouvÃ©
      "kappa": 0.0,           â† Marge de confiance (Phase 2)
      "epsilon": 6.5,         â† Epsilon utilisÃ©
      "success": true,        â† SuccÃ¨s local (surrogate)
      "margin": 5.3,          â† logit_max_wrong - logit_true
      "num_updates": 2        â† Nombre de fois amÃ©liorÃ©
    },
    ...
  }
}
```

**Usage**:
- Ã‰tat persistant entre exÃ©cutions
- Kappas rÃ©utilisÃ©s aux prochains runs
- Phase 2 mettra Ã  jour les kappas automatiquement

---

## ğŸ¯ Que fait le solver ?

### Algorithme: BS-PGD (Binary Search PGD)

Pour chaque image:
1. **Recherche binaire** sur epsilon (8 Ã©tapes)
2. Pour chaque epsilon:
   - **15 restarts alÃ©atoires** (parallÃ©lisÃ©s)
   - Chaque restart: **150 itÃ©rations PGD** avec momentum
3. Garde le **meilleur candidat** (L2 minimal satisfaisant le critÃ¨re)

**CritÃ¨re de succÃ¨s**: `logit_max_wrong - logit_true > Îº`

### Ensemble hybride:

**Groupe A** (ImageNet, 28â†’224):
- ResNet50, DenseNet121, VGG16_BN, EfficientNet_B0
- Cible features sÃ©mantiques haut niveau

**Groupe B** (AdaptÃ©, 28â†’32):
- ResNet18
- Cible patterns bas niveau

**DiversitÃ© d'entrÃ©e**: Scaling, padding, jitter adaptÃ©s pour 28Ã—28

---

## â±ï¸ Performance attendue

### GPU A100 (nÅ“ud de calcul)
- **Par image**: 30-60 secondes
- **100 images**: 60-90 minutes
- **MÃ©moire GPU**: ~6-8 GB / 40 GB

### QualitÃ©
- **Success rate local**: >95%
- **Success rate API**: >85%
- **Leaderboard score**: 0.15-0.20

---

## ğŸ“š Documentation

- `QUICKSTART.md` - Guide rapide
- `README.md` - Documentation complÃ¨te
- `EXECUTION_SUMMARY.md` - DÃ©tails techniques
- `COMMANDES.md` - Ce fichier (rÃ©fÃ©rence rapide)

---

## âœ… Checklist avant lancement

```bash
# 1. VÃ©rifier l'environnement
python preflight_check.py

# 2. VÃ©rifier que le dataset existe
ls -lh ../natural_images.pt

# 3. VÃ©rifier les partitions disponibles
sinfo -p dc-gpu-devel

# 4. Lancer
sbatch run_solver.sh

# 5. VÃ©rifier que le job dÃ©marre
squeue -u $USER

# 6. Surveiller
tail -f logs/slurm_*.out
```

---

## ğŸ”„ Workflow complet

```bash
# Ã‰tape 1: Lancer
sbatch run_solver.sh
# â†’ Attend 60-90 min

# Ã‰tape 2: VÃ©rifier succÃ¨s
python monitor.py
# â†’ VÃ©rifie que submission_run1.npz existe dans output/

# Ã‰tape 3: Analyser (local, rapide)
python analyze.py output/submission_run1.npz --mode local
# â†’ Voir L2 moyen (borne infÃ©rieure)

# Ã‰tape 4: Analyser (API, vrai score)
python analyze.py output/submission_run1.npz --mode api
# â†’ ATTENDRE 15 MIN aprÃ¨s dernier appel API
# â†’ Voir success rate et score rÃ©el

# Ã‰tape 5: Soumettre
python submit.py output/submission_run1.npz
# â†’ ATTENDRE 5 MIN aprÃ¨s derniÃ¨re soumission
# â†’ Score apparaÃ®t sur leaderboard

# Ã‰tape 6 (optionnel): Si success rate < 85%
# â†’ Ã‰diter logs/local_state.json (augmenter kappas images Ã©chouÃ©es)
# â†’ Relancer: sbatch run_solver.sh
```

---

## ğŸ“ Niveau d'implÃ©mentation

**PhD-level** features:
- âœ… Recherche binaire par image (pas epsilon fixe)
- âœ… Multi-restart parallÃ©lisÃ© (pas single-shot)
- âœ… Ensemble hybride (pas naÃ¯f)
- âœ… HyperparamÃ¨tres adaptatifs (pas fixes)
- âœ… Tracking du meilleur candidat (pas dernier iterate)
- âœ… Gestion d'Ã©tat persistante (pas Ã©phÃ©mÃ¨re)
- âœ… Logging production (pas print)

**PrÃªt pour**:
- Phase 2 (feedback loop automatique)
- Publication acadÃ©mique
- Portfolio professionnel

---

**ImplÃ©mentation terminÃ©e. PrÃªt Ã  exÃ©cuter.**

