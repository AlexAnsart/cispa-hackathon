# ğŸš€ START HERE - Guide Ultra-Rapide

## Commande Ã  lancer MAINTENANT (mode rapide)

```bash
cd /p/home/jusers/ansart1/jureca/code/task_1_adversarial_examples/version3
sbatch run_solver_FAST.sh
```

**DurÃ©e**: 6-8 minutes âš¡

---

## Trois modes disponibles

| Mode | Commande | DurÃ©e | Score attendu | Usage |
|------|----------|-------|---------------|-------|
| âš¡ **RAPIDE** | `sbatch run_solver_FAST.sh` | **6-8 min** | 0.18-0.25 | Tests/itÃ©rations |
| âš–ï¸ Ã‰quilibrÃ© | `sbatch run_solver.sh` | 8-12 min | 0.16-0.22 | Production |
| ğŸ¯ QualitÃ© | `sbatch run_solver_QUALITY.sh` | 60-90 min | 0.15-0.20 | Finale |

**Recommandation**: Commence par RAPIDE pour tester !

---

## Analyser les rÃ©sultats (DEUX modes)

### 1. Mode LOCAL (instantanÃ©, sans API) 
```bash
python analyze.py output/submission_fast.npz --mode local
```
- âœ… Rapide (secondes)
- âœ… Pas de rate limit
- âœ… Borne infÃ©rieure du score
- Usage: ItÃ©ration rapide

### 2. Mode API (score rÃ©el, 15 min cooldown)
```bash
python analyze.py output/submission_fast.npz --mode api
```
- âœ… Score RÃ‰EL
- âœ… Voit quelles images Ã©chouent
- âš ï¸ Rate limit: 15 min entre appels
- Usage: Validation finale

---

## Workflow simple

```bash
# 1. Lancer (6-8 min)
sbatch run_solver_FAST.sh

# 2. Surveiller
tail -f logs/slurm_*.out

# 3. Analyser (instantanÃ©)
python analyze.py output/submission_fast.npz --mode local
# â†’ Si L2 moyen < 0.20, c'est bon !

# 4. VÃ©rifier score rÃ©el (15 min cooldown)
python analyze.py output/submission_fast.npz --mode api
# â†’ Si success rate > 80%, excellent !

# 5. Soumettre (5 min cooldown)
python submit.py output/submission_fast.npz
```

---

## InterprÃ©tation rapide

### Analyse locale
```
Average (normalized): 0.1834
```
â†’ **Borne infÃ©rieure**. Score rÃ©el sera >= 0.1834

### Analyse API
```
Success Rate: 87/100 (87.0%)
Leaderboard Score: 0.1876
```
â†’ **Score rÃ©el**. C'est ce qui compte.

**Objectif**: Success > 85%, Score < 0.20

---

## Que faire maintenant ?

### Option 1: Test ultra-rapide (RECOMMANDÃ‰)
```bash
sbatch run_solver_FAST.sh
# â†’ Attends 6-8 min
python analyze.py output/submission_fast.npz --mode local
# â†’ Vois si c'est prometteur
```

### Option 2: VÃ©rifier environnement d'abord
```bash
python preflight_check.py
# â†’ VÃ©rifie que tout est OK
sbatch run_solver_FAST.sh
```

### Option 3: Directement production
```bash
sbatch run_solver.sh
# â†’ 8-12 min, meilleure qualitÃ©
```

---

## Fichiers importants

- **`COMMANDES_UPDATED.md`** â† Guide complet des commandes
- **`START_HERE.md`** â† Ce fichier (dÃ©marrage rapide)
- **`README.md`** â† Documentation technique

---

## Surveiller la progression

```bash
# Dashboard
python monitor.py

# Logs en direct
tail -f logs/slurm_*.out

# Job status
squeue -u $USER
```

---

## Questions frÃ©quentes

**Q: Quel mode choisir ?**
A: FAST pour tester, QUALITY pour submission finale

**Q: Mode local ou API pour analyser ?**
A: Local pour itÃ©rer vite, API pour score rÃ©el (15 min cooldown)

**Q: Combien de temps Ã§a prend ?**
A: FAST = 6-8 min, Standard = 8-12 min, QUALITY = 60-90 min

**Q: Quel score viser ?**
A: < 0.20 est compÃ©titif, < 0.15 est excellent

**Q: Success rate minimum ?**
A: Viser > 85% (chaque Ã©chec coÃ»te 1.0 au score)

---

## LANCE MAINTENANT âš¡

```bash
cd /p/home/jusers/ansart1/jureca/code/task_1_adversarial_examples/version3
sbatch run_solver_FAST.sh
```

**RÃ©sultats dans 6-8 minutes ! ğŸš€**

